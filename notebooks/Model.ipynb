{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6722e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, axis=(1, 2, 3)):\n",
    "    \"\"\"\n",
    "    Compute mean dice coefficient over all class\n",
    "    \n",
    "    Args:\n",
    "        y_true (Tensorflow tensor): tensor of ground truth\n",
    "                                    shape: (num_class, x_dim, y_dim, z_dim)\n",
    "        y_pred (Tensorflow tensor): tensor of soft prediction for all classes\n",
    "                                    shape: (num_class, x_dim, y_dim, z_dim)\n",
    "        axis (tuple): spatial axis to sum over\n",
    "        epsilon (float): small constant added to avoid divide by 0 error\n",
    "    Return:\n",
    "        dice_coefficient (float): computed value of dice coefficient\n",
    "    \"\"\"\n",
    "    \n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true, axis=axis) + K.sum(y_pred, axis=axis) + epsilon\n",
    "    dice_coefficient = K.mean(dice_numerator / dice_denominator)\n",
    "    \n",
    "    return dice_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c87b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3), epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Compute mean soft dice loss over all classes\n",
    "    \n",
    "    Args:\n",
    "        y_true (Tensorflow tensor): tensor of ground truth\n",
    "                                    shape: (num_class, x_dim, y_dim, z_dim)\n",
    "        y_pred (Tensorflow tensor): tensor of soft prediction for all classes\n",
    "                                    shape: (num_class, x_dim, y_dim, z_dim)\n",
    "        axis (tuple): spatial axis to sum over\n",
    "        epsilon (float): small constant added to avoid divide by 0 error\n",
    "        \n",
    "    Return:\n",
    "        dice_loss (float): computed value of dice loss\n",
    "    \"\"\"\n",
    "    \n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true**2, axis=axis) + K.sum(y_pred**2, axis=axis) + epsilon\n",
    "    dice_loss = 1 - K.mean(dice_numerator / dice_denominator)\n",
    "    \n",
    "    return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolution_block(input_layer, n_filters, batch_normalization=False,\n",
    "                             kernel=(3, 3, 3), activation=None,\n",
    "                             padding='same', strides=(1, 1, 1),\n",
    "                             instance_normalization=False):\n",
    "    \"\"\"\n",
    "    :param strides:\n",
    "    :param input_layer:\n",
    "    :param n_filters:\n",
    "    :param batch_normalization:\n",
    "    :param kernel:\n",
    "    :param activation: Keras activation layer to use. (default is 'relu')\n",
    "    :param padding:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(\n",
    "        input_layer)\n",
    "    if activation is None:\n",
    "        return Activation('relu')(layer)\n",
    "    else:\n",
    "        return activation()(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c92a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_up_convolution(n_filters, pool_size, kernel_size=(2, 2, 2),\n",
    "                       strides=(2, 2, 2),\n",
    "                       deconvolution=False):\n",
    "    if deconvolution:\n",
    "        return Conv3DTranspose(filters=n_filters, kernel_size=kernel_size,\n",
    "                               strides=strides)\n",
    "    else:\n",
    "        return UpSampling3D(size=pool_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0af0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model_3d(loss_function, input_shape=(4, 160, 160, 16),\n",
    "                  pool_size=(2, 2, 2), n_labels=3,\n",
    "                  initial_learning_rate=0.00001,\n",
    "                  deconvolution=False, depth=4, n_base_filters=32,\n",
    "                  include_label_wise_dice_coefficients=False, metrics=[],\n",
    "                  batch_normalization=False, activation_name=\"sigmoid\"):\n",
    "    \"\"\"\n",
    "    Builds the 3D UNet Keras model.f\n",
    "    :param metrics: List metrics to be calculated during model training (default is dice coefficient).\n",
    "    :param include_label_wise_dice_coefficients: If True and n_labels is greater than 1, model will report the dice\n",
    "    coefficient for each label as metric.\n",
    "    :param n_base_filters: The number of filters that the first layer in the convolution network will have. Following\n",
    "    layers will contain a multiple of this number. Lowering this number will likely reduce the amount of memory required\n",
    "    to train the model.\n",
    "    :param depth: indicates the depth of the U-shape for the model. The greater the depth, the more max pooling\n",
    "    layers will be added to the model. Lowering the depth may reduce the amount of memory required for training.\n",
    "    :param input_shape: Shape of the input data (n_chanels, x_size, y_size, z_size). The x, y, and z sizes must be\n",
    "    divisible by the pool size to the power of the depth of the UNet, that is pool_size^depth.\n",
    "    :param pool_size: Pool size for the max pooling operations.\n",
    "    :param n_labels: Number of binary labels that the model is learning.\n",
    "    :param initial_learning_rate: Initial learning rate for the model. This will be decayed during training.\n",
    "    :param deconvolution: If set to True, will use transpose convolution(deconvolution) instead of up-sampling. This\n",
    "    increases the amount memory required during training.\n",
    "    :return: Untrained 3D UNet Model\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    current_layer = inputs\n",
    "    levels = list()\n",
    "\n",
    "    # add levels with max pooling\n",
    "    for layer_depth in range(depth):\n",
    "        layer1 = create_convolution_block(input_layer=current_layer,\n",
    "                                          n_filters=n_base_filters * (\n",
    "                                                  2 ** layer_depth),\n",
    "                                          batch_normalization=batch_normalization)\n",
    "        layer2 = create_convolution_block(input_layer=layer1,\n",
    "                                          n_filters=n_base_filters * (\n",
    "                                                  2 ** layer_depth) * 2,\n",
    "                                          batch_normalization=batch_normalization)\n",
    "        if layer_depth < depth - 1:\n",
    "            current_layer = MaxPooling3D(pool_size=pool_size)(layer2)\n",
    "            levels.append([layer1, layer2, current_layer])\n",
    "        else:\n",
    "            current_layer = layer2\n",
    "            levels.append([layer1, layer2])\n",
    "\n",
    "    # add levels with up-convolution or up-sampling\n",
    "    for layer_depth in range(depth - 2, -1, -1):\n",
    "        \n",
    "        #print(K.int_shape(current_layer)[1])\n",
    "        up_convolution = get_up_convolution(pool_size=pool_size,\n",
    "                                            deconvolution=deconvolution,\n",
    "                                            n_filters=K.int_shape(current_layer)[1])(current_layer)\n",
    "        \n",
    "        concat = concatenate([up_convolution, levels[layer_depth][1]], axis=1)\n",
    "        \n",
    "        #print(K.int_shape(levels[layer_depth][1])[1])\n",
    "        current_layer = create_convolution_block(n_filters= K.int_shape(levels[layer_depth][1])[1],\n",
    "                                                 input_layer=concat, \n",
    "                                                 batch_normalization=batch_normalization)\n",
    "        \n",
    "        current_layer = create_convolution_block(n_filters= K.int_shape(levels[layer_depth][1])[1],\n",
    "                                                 input_layer=current_layer,\n",
    "                                                 batch_normalization=batch_normalization)\n",
    "\n",
    "    final_convolution = Conv3D(n_labels, (1, 1, 1))(current_layer)\n",
    "    act = Activation(activation_name)(final_convolution)\n",
    "    model = Model(inputs=inputs, outputs=act)\n",
    "\n",
    "    if not isinstance(metrics, list):\n",
    "        metrics = [metrics]\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=initial_learning_rate), loss=loss_function,\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058fd95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
